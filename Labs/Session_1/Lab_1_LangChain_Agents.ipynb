{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: LangChain Agents\n",
    "\n",
    "**Objective:** Build a research assistant agent with custom tools, memory, and debugging capabilities.\n",
    "\n",
    "**Duration:** ~45 minutes\n",
    "\n",
    "**What You'll Learn:**\n",
    "- How to create custom tools using the `@tool` decorator\n",
    "- How to build agents with the ReAct pattern\n",
    "- How to add conversational memory\n",
    "- How to debug agent behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Imports\n",
    "\n",
    "First, let's import the required libraries and configure our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found in environment\"\n",
    "print(\"Environment configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import tool\n",
    "from langchain import hub\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Tools\n",
    "\n",
    "Tools are functions that agents can call to interact with the outside world. In LangChain, we use the `@tool` decorator to define them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple calculator tool\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluates a mathematical expression and returns the result.\n",
    "    Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression like '2 + 2' or '15 * 7'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Only allow safe mathematical operations\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"Error: Invalid characters in expression\"\n",
    "        result = eval(expression)\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {str(e)}\"\n",
    "\n",
    "# Test the tool\n",
    "print(calculator.invoke(\"15 * 7 + 3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current date/time tool\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Returns the current date and time. Use this when you need to know what time or date it is.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return f\"Current date and time: {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# Test the tool\n",
    "print(get_current_datetime.invoke(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web search tool using Tavily\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Check if Tavily API key is available\n",
    "if os.getenv(\"TAVILY_API_KEY\"):\n",
    "    search_tool = TavilySearchResults(\n",
    "        max_results=3,\n",
    "        description=\"Search the web for current information. Use this when you need up-to-date information.\"\n",
    "    )\n",
    "    print(\"Tavily search tool configured!\")\n",
    "else:\n",
    "    # Fallback mock search for demo purposes\n",
    "    @tool\n",
    "    def search_tool(query: str) -> str:\n",
    "        \"\"\"Search the web for information (mock version).\"\"\"\n",
    "        return f\"Mock search results for: {query}. In production, configure TAVILY_API_KEY for real search.\"\n",
    "    print(\"Using mock search tool (set TAVILY_API_KEY for real search)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building Your First Agent\n",
    "\n",
    "Now let's build an agent that can use these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0  # Lower temperature for more consistent behavior\n",
    ")\n",
    "\n",
    "# Define our tools list\n",
    "tools = [calculator, get_current_datetime, search_tool]\n",
    "\n",
    "print(f\"Configured {len(tools)} tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}: {tool.description[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ReAct prompt from LangChain hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Let's examine the prompt structure\n",
    "print(\"ReAct Prompt Template:\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt.template[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Wrap in an executor with verbose mode for debugging\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,  # Shows the agent's thought process\n",
    "    max_iterations=5,  # Prevent infinite loops\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with a simple query\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What is 15 multiplied by 7, and what time is it right now?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Final Answer:\", response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Agent's Reasoning\n",
    "\n",
    "Notice how the agent:\n",
    "1. **Thought** about what tools it needs\n",
    "2. **Acted** by calling the appropriate tool\n",
    "3. **Observed** the result\n",
    "4. **Repeated** until it had all the information\n",
    "5. **Responded** with the final answer\n",
    "\n",
    "This is the **ReAct** (Reason + Act) pattern in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Adding Custom Tools\n",
    "\n",
    "Let's create more sophisticated custom tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather tool (simulated)\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city to get weather for\n",
    "    \"\"\"\n",
    "    # In production, this would call a real weather API\n",
    "    import random\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"partly cloudy\"]\n",
    "    temp = random.randint(50, 85)\n",
    "    condition = random.choice(conditions)\n",
    "    return f\"Weather in {city}: {temp}Â°F, {condition}\"\n",
    "\n",
    "# Test it\n",
    "print(get_weather.invoke(\"San Francisco\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note-taking tool with state\n",
    "notes_storage = []\n",
    "\n",
    "@tool\n",
    "def save_note(note: str) -> str:\n",
    "    \"\"\"Save a note for later reference.\n",
    "    \n",
    "    Args:\n",
    "        note: The note content to save\n",
    "    \"\"\"\n",
    "    notes_storage.append(note)\n",
    "    return f\"Note saved! You now have {len(notes_storage)} note(s).\"\n",
    "\n",
    "@tool\n",
    "def get_notes() -> str:\n",
    "    \"\"\"Retrieve all saved notes.\"\"\"\n",
    "    if not notes_storage:\n",
    "        return \"No notes saved yet.\"\n",
    "    return \"Saved notes:\\n\" + \"\\n\".join(f\"- {note}\" for note in notes_storage)\n",
    "\n",
    "# Test\n",
    "print(save_note.invoke(\"Remember to review LangChain docs\"))\n",
    "print(get_notes.invoke(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enhanced agent with all tools\n",
    "enhanced_tools = [calculator, get_current_datetime, search_tool, get_weather, save_note, get_notes]\n",
    "\n",
    "enhanced_agent = create_react_agent(llm, enhanced_tools, prompt)\n",
    "\n",
    "enhanced_executor = AgentExecutor(\n",
    "    agent=enhanced_agent,\n",
    "    tools=enhanced_tools,\n",
    "    verbose=True,\n",
    "    max_iterations=10,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(f\"Enhanced agent with {len(enhanced_tools)} tools ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the enhanced agent\n",
    "response = enhanced_executor.invoke({\n",
    "    \"input\": \"What's the weather in New York? Save a note about it.\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Final Answer:\", response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding Memory\n",
    "\n",
    "Agents become more useful when they can remember previous interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the conversational ReAct prompt\n",
    "conversational_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "print(\"Conversational prompt loaded!\")\n",
    "print(\"\\nInput variables:\", conversational_prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Create conversational agent\n",
    "conversational_agent = create_react_agent(llm, enhanced_tools, conversational_prompt)\n",
    "\n",
    "conversational_executor = AgentExecutor(\n",
    "    agent=conversational_agent,\n",
    "    tools=enhanced_tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    max_iterations=10,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"Conversational agent with memory ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First interaction\n",
    "response1 = conversational_executor.invoke({\n",
    "    \"input\": \"My name is Alice. What's the weather in Seattle?\"\n",
    "})\n",
    "print(\"\\nResponse 1:\", response1[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second interaction - the agent should remember the name\n",
    "response2 = conversational_executor.invoke({\n",
    "    \"input\": \"What's my name? And save a note that says I'm interested in Seattle weather.\"\n",
    "})\n",
    "print(\"\\nResponse 2:\", response2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third interaction - check memory and notes\n",
    "response3 = conversational_executor.invoke({\n",
    "    \"input\": \"What notes do we have? Summarize our conversation.\"\n",
    "})\n",
    "print(\"\\nResponse 3:\", response3[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Debugging and Best Practices\n",
    "\n",
    "Let's explore techniques for debugging and improving agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LangChain debugging\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "\n",
    "# Uncomment to enable detailed debugging\n",
    "# set_debug(True)\n",
    "set_verbose(True)\n",
    "\n",
    "print(\"Debug settings configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom error handling tool\n",
    "@tool\n",
    "def risky_operation(data: str) -> str:\n",
    "    \"\"\"A tool that might fail - for demonstrating error handling.\n",
    "    \n",
    "    Args:\n",
    "        data: Input data to process\n",
    "    \"\"\"\n",
    "    if \"error\" in data.lower():\n",
    "        raise ValueError(\"Simulated error for demonstration\")\n",
    "    return f\"Successfully processed: {data}\"\n",
    "\n",
    "# The agent with handle_parsing_errors=True will gracefully handle this\n",
    "print(\"Risky operation tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practice: Create well-documented tools\n",
    "@tool\n",
    "def analyze_sentiment(text: str) -> str:\n",
    "    \"\"\"Analyze the sentiment of a given text.\n",
    "    \n",
    "    This tool examines text and determines if the overall sentiment\n",
    "    is positive, negative, or neutral. Use this when you need to\n",
    "    understand how someone feels about something based on their writing.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze for sentiment\n",
    "        \n",
    "    Returns:\n",
    "        A string describing the sentiment (positive, negative, or neutral)\n",
    "        along with confidence indicators.\n",
    "    \"\"\"\n",
    "    # Simplified sentiment analysis\n",
    "    positive_words = ['good', 'great', 'excellent', 'happy', 'love', 'amazing', 'wonderful']\n",
    "    negative_words = ['bad', 'terrible', 'awful', 'sad', 'hate', 'horrible', 'disappointing']\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "    neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        return f\"Sentiment: POSITIVE (found {pos_count} positive indicators)\"\n",
    "    elif neg_count > pos_count:\n",
    "        return f\"Sentiment: NEGATIVE (found {neg_count} negative indicators)\"\n",
    "    else:\n",
    "        return \"Sentiment: NEUTRAL (no strong indicators found)\"\n",
    "\n",
    "# Test\n",
    "print(analyze_sentiment.invoke(\"I love this amazing product! It's wonderful.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Build Your Own Research Agent\n",
    "\n",
    "Now it's your turn! Create a research assistant agent with the following capabilities:\n",
    "\n",
    "1. **Web search** - Find current information\n",
    "2. **Note taking** - Save important findings\n",
    "3. **Calculator** - Perform calculations\n",
    "4. **Summary tool** - Summarize findings\n",
    "\n",
    "The agent should be able to:\n",
    "- Research a topic\n",
    "- Save key findings as notes\n",
    "- Perform any needed calculations\n",
    "- Provide a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a summary tool\n",
    "@tool\n",
    "def summarize_research() -> str:\n",
    "    \"\"\"Summarize all research findings from saved notes.\n",
    "    \n",
    "    Use this after gathering information to create a summary\n",
    "    of all saved notes.\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    # Hint: Use the notes_storage list\n",
    "    pass\n",
    "\n",
    "# TODO: Create your research agent with all the tools\n",
    "# research_tools = [...]\n",
    "# research_agent = create_react_agent(...)\n",
    "# research_executor = AgentExecutor(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your research agent\n",
    "# Example query: \"Research the current state of AI in healthcare. \n",
    "#                 Save the key findings and provide a summary.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Summary\n",
    "\n",
    "In this lab, you learned:\n",
    "\n",
    "1. **Tool Creation**: Using `@tool` decorator to create agent tools\n",
    "2. **ReAct Pattern**: How agents reason and act in a loop\n",
    "3. **Agent Building**: Creating agents with `create_react_agent`\n",
    "4. **Memory**: Adding conversational memory with `ConversationBufferMemory`\n",
    "5. **Debugging**: Using verbose mode and debugging tools\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Good tool descriptions are **critical** - they help the agent understand when to use each tool\n",
    "- Use `verbose=True` during development to understand agent behavior\n",
    "- Set `max_iterations` to prevent infinite loops\n",
    "- Memory enables multi-turn conversations\n",
    "- Error handling (`handle_parsing_errors=True`) makes agents more robust\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lab 2, you'll learn about multi-agent systems with AutoGen and CrewAI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "set_verbose(False)\n",
    "print(\"Lab 1 complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
